# From Existential Threat To Hope. A Philosopher’s Guide To AI

By [Pia Lauritzen](https://archive.is/o/fQJWr/https://www.forbes.com/sites/pialauritzen/),

Published Jul 06, 2025, 11:29am EDT, Updated Jul 07, 2025, 05:16am EDT

The dark side of AI continues to reveal new faces. A few weeks ago, Geoffrey Hinton, Nobel laureate and former AI chief in Google, highlighted two ways in which [AI poses an existential threat to humanity](https://archive.is/o/fQJWr/https://www.forbes.com/sites/pialauritzen/2025/06/22/the-biggest-existential-threat-calls-for-philosophers-not-ai-experts/): By people misusing AI, and by AI becoming smarter than us. And this week OpenAI admitted that they don’t know how to prevent ChatGPT from [pushing people towards mania, psychosis and death](https://archive.is/o/fQJWr/https://www.independent.co.uk/tech/chatgpt-psychosis-ai-therapy-chatbot-b2781202.html).

At the same time, AI optimists keep stressing that it is [only a matter of years](https://archive.is/o/fQJWr/https://officechai.com/ai/ai-could-solve-a-millennium-prize-problem-in-2-5-years-openai-president-greg-brockman/) before AI will solve scientific, environmental, health and social problems that humanity has been struggling with for ages. And when The United Nations kicks off its [global summit on AI for Good](https://archive.is/o/fQJWr/https://aiforgood.itu.int/) next week, it’s to gather AI experts from across the world to "identify innovative AI applications to solve global challenges.”

But what if the discussion of AI’s risks and opportunities, dark and bright sides and bad and good ways to use technology is part of the existential threat we are facing?

## Why AI For Good May Be A Bad Idea

When German philosopher Friedrich Nietzsche urged us to think _Beyond Good and Evil_ (book from 1885), he suggested that it is not what we identify, define, and decide to be 'good’ that determines whether we succeed as humans. It is whether we manage to rise above our unquestioned ideas of what good looks like.

Labeling some AI products as human-centric or responsible might sound like a step in the right direction towards identifying and designing innovative AI applications to solve global challenges. But it also reinforces the idea that our future depends on how AI is designed, built and regulated rather on how we live, learn and relate to technology.

And by focusing on AI when thinking and talking about our future rather than focusing on ourselves and how we exist and evolve as humans, we are not rising above our unquestioned ideas of what good looks like. Rather, we submit to the idea that permeates all technology, that good equals innovative, fast, and efficient.

To rise above our unquestioned ideas about the nature and impact of AI, we need to follow Nietzsche’s lead. So, here it is: A Philosopher’s Guide to AI.

## 1. Stop Thinking Of AI As A Tool

The first step towards shifting the focus from the development of AI to our evolution as humans is to question the widespread and constantly repeated idea that AI, like any other technology, is [just a tool](https://archive.is/o/fQJWr/https://www.forbes.com/councils/forbestechcouncil/2024/11/06/ai-as-a-partner-enhancing-human-intelligence-and-driving-innovation-across-industries/) that can be used for good as well as evil. Inspired by Nietzsche and others who set the tradition of existential philosophy in motion, German philosopher Martin Heidegger put it like this:

”Everywhere we remain unfree and chained to technology, whether we passionately affirm or deny it. But we are delivered over to it in the worst possible way when we regard is as something neutral; for this conception of it, to which today we particularly like to pay homage, makes us utterly blind to the essence of technology.”

In _The Question Concerning Technology_ from 1954, Heidegger argued that the essence of technology is to give man the illusion of being in control. When we think of technology as a tool that can be used for good as well as evil, we also think that we are in control of why, when, and for what it is used. But according to Heidegger this is only partly the case. We may make a decision to buy a car to drive ourselves to work. And thus we may think of the car as a means to achieve our goal of getting to work as fast as possible. But we never made the decision that fast is better than slow. It’s an idea that comes with the car. So is the idea that it should be easy and convenient for us to get to work. And that fast, easy and convenient is more important than anything else.

Like all other technologies, the car comes with a promise that we can achieve more by doing less. And like all other technologies, it makes us think that this is what life is and should be about. But to rise above our unquestioned ideas, we must not only ask the questions we are encouraged to ask when faced with a new technology – like ‘how does it work?’, ‘when can I use it?’, and ‘how much easier will it be to do X?’ We must also ask the questions that the essence of technology discourages us from asking – like ‘do I even need technology for this?’, ‘what does this technology prevent me from doing?’, and ‘what will my life be like if I trust technology to make everything easy?’

## 2. Take The History Of Technology Seriously

Heidegger made it clear that although different generations of technology have different ways of influencing human beings and behaviors, our [fundamental purpose for using technology](https://archive.is/o/fQJWr/https://www.strategy-business.com/blog/The-art-of-leading-in-the-AI-age) remains the same: to deal with the fact that we are limited creatures, thrown into this world without knowing why and for how long.

Put differently, the question concerning technology is and always was existential. It’s about who we are and what we become when we try to overcome our limitations. Ever since our early ancestors began using rocks and branches as tools and weapons, our relationship with technology has been at the heart of how we live, learn and evolve as humans. And more than anything else, it has shaped our understanding of ourselves and our relationship with our surroundings.

Living in the early days of the digital revolution, Heidegger didn’t know that AI would have the impact it has today. Nor did he know that AI experts would talk about their inventions as posing an existential threat to humanity. But he distinguished between different generations of technology. And he suggested that humanity was moving toward a technological era of great existential significance.

![[Pasted image 20250708231534.png]]

Having used pre-modern tools to _survive_ and modern technology to _thrive_, the idea that digital technology can help _transcend_ the limitations set by nature doesn’t seem far-fetched (see illustration). However, by not realizing that our relationship with technology is existential, AI experts seem to have missed that AI was never just a tool to make us more productive, or to help us do ‘good’. It was always also an expression of who we are and what we are becoming. And by building technology that distances itself from the limitations of nature, we also began to distance ourselves from our human nature.

According to Heidegger, this distancing has been going on for centuries without any of us noticing it. The widespread debate about AI as an existential threat is a sign that this is changing. And that AI may be the starting point for us humans to finally develop a more reflective and healthy relationship with technology.

## 3. Make Existential Hope A Joint Venture

Heidegger concludes _The Question Concerning Technology_ by writing:

“The closer we come to the danger, the brighter the ways into the saving power begin to shine and the more questioning we become. For questioning is the piety of thought.”

While AI experts are calling for regulation, for AI development to be paused, and even for new philosophers to help them deal with the threat they see AI posing, hope shines from a completely different place than tech companies and regulators.

‘Where?’ you may ask. And that’s just it. We are asking more existential questions about who we are, why we are here, and where we want to go as humanity than ever before. And with ‘we’, I don’t mean philosophers, tech experts, and decision makers. I mean all of us in all sorts of contexts in all parts of the world.

There is something about AI that, unlike previous generations of technology, makes us ask the questions that the essence of technology has previously discouraged us from asking. Unlike modern technologies like cars and digital technologies like computers, we actually have a widespread debate about what AI is preventing us from doing and what our lives will be like if we trust AI to make everything easy.

And this instills hope. Existential hope that we still know and are willing to do what it takes to stay human. Even when it doesn’t equal innovative, fast, and efficient.

Senior journalist with BBC Global News, Richard Fisher defines [existential hope](https://archive.is/o/fQJWr/https://bigthink.com/thinking/existential-hope-embrace-deep-time-bright-future/) as "the opposite of existential catastrophe: It’s the idea that there could be radical turns for the better, so long as we commit to bringing them to reality. Existential hope is not about escapism, utopias or pipe dreams, but about preparing the ground: making sure that opportunities for a better world don’t pass us by.” With A Philosopher’s Guide to AI, the questions we ask about AI offers a once in many lifetimes opportunity for a better world. Let’s make sure it doesn’t pass us by!
